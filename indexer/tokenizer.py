# indexer/tokenizer.py

def tokenize(text):
    """
    Tokenize and lemmatize the text:
    - Convert text to lowercase
    - Tokenize using NLTK
    - Apply lemmatization to each token
    """
    pass
